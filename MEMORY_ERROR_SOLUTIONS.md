## ğŸ”§ ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆã®å¯¾å‡¦æ³•

Colabã§ `CUDA out of memory` ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆï¼š

### è§£æ±ºæ–¹æ³•1: ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ä¸‹ã’ã‚‹ï¼ˆæœ€ã‚‚åŠ¹æœçš„ï¼‰

```bash
# batch_size ã‚’ 8 â†’ 4 ã«å¤‰æ›´
/Users/yoppii/Desktop/code/watermark/.venv/bin/python src/train.py \
  --clean-dir data/train/clean \
  --watermarked-dir data/train/watermarked \
  --epochs 100 \
  --batch-size 4 \
  --val-split 0.1

# ãã‚Œã§ã‚‚ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆ: 2 ã«å¤‰æ›´
/Users/yoppii/Desktop/code/watermark/.venv/bin/python src/train.py \
  --clean-dir data/train/clean \
  --watermarked-dir data/train/watermarked \
  --epochs 100 \
  --batch-size 2 \
  --val-split 0.1
```

### è§£æ±ºæ–¹æ³•2: ç”»åƒã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹

`config/config.yaml` ã‚’ç·¨é›†ï¼š

```yaml
image:
  input_size: [256, 256]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® [512, 512] ã‹ã‚‰å¤‰æ›´
```

### è§£æ±ºæ–¹æ³•3: GPUãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢ï¼ˆColabã®å ´åˆï¼‰

```python
import torch
import gc

# GPUãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢
torch.cuda.empty_cache()
gc.collect()

# GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã‚’ç¢ºèª
print(torch.cuda.memory_summary())
```

### è§£æ±ºæ–¹æ³•4: ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•

Colabä¸Šéƒ¨ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼:
1. ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€â†’ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•ã€
2. ã‚»ãƒ«ã‚’æœ€åˆã‹ã‚‰å†å®Ÿè¡Œ

### ãƒãƒƒãƒã‚µã‚¤ã‚ºã®ç›®å®‰

| GPU | VRAM | æ¨å¥¨ batch_size | ç”»åƒã‚µã‚¤ã‚º 512x512 |
|-----|------|----------------|-------------------|
| Google Colab T4 | 15GB | 4-8 | âœ… |
| Apple M1/M2 (MPS) | 8-16GB | 2-4 | âœ… |
| CPU | - | 1-2 | âš ï¸ é…ã„ |

### ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¾‹

```
torch.OutOfMemoryError: CUDA out of memory. 
Tried to allocate 1024.00 MiB. 
GPU 0 has a total capacity of 14.74 GiB of which 54.12 MiB is free.
```

**â†’ ã“ã®å ´åˆ**: batch_size ã‚’åŠåˆ†ã«æ¸›ã‚‰ã—ã¦ãã ã•ã„

---

**æ¨å¥¨ã®å­¦ç¿’è¨­å®š (Colab T4 GPU)**:

```bash
!python src/train.py \
  --clean-dir data/train/clean \
  --watermarked-dir data/train/watermarked \
  --epochs 100 \
  --batch-size 4 \
  --val-split 0.1
```

ã“ã®è¨­å®šãªã‚‰å®‰å®šã—ã¦å­¦ç¿’ã§ãã¾ã™ï¼
